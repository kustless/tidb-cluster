apiVersion: v1
data:
  config-file: |-
    # PD Configuration.

    name = "pd"
    data-dir = "default.pd"

    client-urls = "http://127.0.0.1:2379"
    # if not set, use ${client-urls}
    advertise-client-urls = ""

    peer-urls = "http://127.0.0.1:2380"
    # if not set, use ${peer-urls}
    advertise-peer-urls = ""

    initial-cluster = ""
    initial-cluster-state = ""

    lease = 3
    tso-save-interval = "3s"

    namespace-classifier = "table"

    enable-prevote = true

    [security]
    # Path of file that contains list of trusted SSL CAs. if set, following four settings shouldn't be empty
    cacert-path = ""
    # Path of file that contains X509 certificate in PEM format.
    cert-path = ""
    # Path of file that contains X509 key in PEM format.
    key-path = ""

    [log]
    level = "info"

    # log format, one of json, text, console
    #format = "text"

    # disable automatic timestamps in output
    #disable-timestamp = false

    # file logging
    [log.file]
    #filename = ""
    # max log file size in MB
    #max-size = 300
    # max log file keep days
    #max-days = 28
    # maximum number of old log files to retain
    #max-backups = 7
    # rotate log by day
    #log-rotate = true

    [metric]
    # prometheus client push interval, set "0s" to disable prometheus.
    interval = "15s"
    # prometheus pushgateway address, leaves it empty will disable prometheus.
    address = ""

    [schedule]
    max-merge-region-size = 0
    max-merge-region-keys = 0
    split-merge-interval = "1h"
    max-snapshot-count = 3
    max-pending-peer-count = 16
    max-store-down-time = "30m"
    leader-schedule-limit = 4
    region-schedule-limit = 4
    replica-schedule-limit = 8
    merge-schedule-limit = 8
    tolerant-size-ratio = 5.0

    # customized schedulers, the format is as below
    # if empty, it will use balance-leader, balance-region, hot-region as default
    # [[schedule.schedulers]]
    # type = "evict-leader"
    # args = ["1"]

    [replication]
    # The number of replicas for each region.
    max-replicas = 3
    # The label keys specified the location of a store.
    # The placement priorities is implied by the order of label keys.
    # For example, ["zone", "rack"] means that we should place replicas to
    # different zones first, then to different racks if we don't have enough zones.
    location-labels = ["region", "zone", "rack", "host"]

    [label-property]
    # Do not assign region leaders to stores that have these tags.
    #  [[label-property.reject-leader]]
    #  key = "zone"
    #  value = "cn1
  startup-script: |-
    #!/bin/sh

    # This script is used to start pd containers in kubernetes cluster

    # Use DownwardAPIVolumeFiles to store informations of the cluster:
    # https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#the-downward-api
    #
    #   runmode="normal/debug"
    #

    set -uo pipefail



    ANNOTATIONS="/etc/podinfo/annotations"

    if [[ ! -f "${ANNOTATIONS}" ]]
    then
        echo "${ANNOTATIONS} does't exist, exiting."
        exit 1
    fi
    source ${ANNOTATIONS} 2>/dev/null

    runmode=${runmode:-normal}
    if [[ X${runmode} == Xdebug ]]
    then
        echo "entering debug mode."
        tail -f /dev/null
    fi

    # the general form of variable PEER_SERVICE_NAME is: "<clusterName>-pd-peer"
    cluster_name=`echo ${PEER_SERVICE_NAME} | sed 's/-pd-peer//'`
    domain="${HOSTNAME}.${PEER_SERVICE_NAME}.${NAMESPACE}.svc"
    discovery_url="${cluster_name}-discovery.${NAMESPACE}.svc:10261"
    encoded_domain_url=`echo ${domain}:2380 | base64 | tr "\n" " " | sed "s/ //g"`

    elapseTime=0
    period=1
    threshold=30
    while true; do
        sleep ${period}
        elapseTime=$(( elapseTime+period ))

        if [[ ${elapseTime} -ge ${threshold} ]]
        then
            echo "waiting for pd cluster ready timeout" >&2
            exit 1
        fi

        if nslookup ${domain} 2>/dev/null
        then
            echo "nslookup domain ${domain}.svc success"
            break
        else
            echo "nslookup domain ${domain} failed" >&2
        fi
    done

    ARGS="--data-dir=/var/lib/pd \
    --name=${HOSTNAME} \
    --peer-urls=http://0.0.0.0:2380 \
    --advertise-peer-urls=http://${domain}:2380 \
    --client-urls=http://0.0.0.0:2379 \
    --advertise-client-urls=http://${domain}:2379 \
    --config=/etc/pd/pd.toml \
    "

    if [[ -f /var/lib/pd/join ]]
    then
        # The content of the join file is:
        #   demo-pd-0=http://demo-pd-0.demo-pd-peer.demo.svc:2380,demo-pd-1=http://demo-pd-1.demo-pd-peer.demo.svc:2380
        # The --join args must be:
        #   --join=http://demo-pd-0.demo-pd-peer.demo.svc:2380,http://demo-pd-1.demo-pd-peer.demo.svc:2380
        join=`cat /var/lib/pd/join | tr "," "\n" | awk -F'=' '{print $2}' | tr "\n" ","`
        join=${join%,}
        ARGS="${ARGS} --join=${join}"
    elif [[ ! -d /var/lib/pd/member/wal ]]
    then
        until result=$(wget -qO- -T 3 http://${discovery_url}/new/${encoded_domain_url} 2>/dev/null); do
            echo "waiting for discovery service returns start args ..."
            sleep $((RANDOM % 5))
        done
        ARGS="${ARGS}${result}"
    fi

    echo "starting pd-server ..."
    sleep $((RANDOM % 10))
    echo "/pd-server ${ARGS}"
    exec /pd-server ${ARGS}
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: pd
    app.kubernetes.io/instance: tidb-cluster
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/name: tidb-cluster
    helm.sh/chart: tidb-cluster-dev
  name: tidb-cluster-pd
